#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74

import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import dataLoader

#dataFilePath = 'C:/Users/faqeerrehman/MSU/OneDrive - Montana State University/CourseWork/SecondSemester/MachineLearning/CourseProject/IntrustionDetectionSystem/Pilot1/P1B2Tests/Data/ML4ML/4_MergedDataset.csv'
#dataFilePath = 'C:/Users/faqeerrehman/MSU/OneDrive - Montana State University/Research/Clem/ResearchPaperDNN3/Results20Epochs/Research2/DataSet/train.csv'
#dataFilePath = 'C:/Users/faqeerrehman/MSU/OneDrive - Montana State University/Research/Clem/ResearchPaperDNN3/Results20Epochs/Research2/DataSetWithHighAccuracy/NewDS/MR0/train.csv'


##WithoutMetaDataFeatures####
dataFilePath = '/DataSetWithHighAccuracy/MR0/GeneratedDataSet/WithOutMetaDataFeatures/train.csv'
##WithMetaDataFeatures####
#dataFilePath = '/DataSetWithHighAccuracy/MR0/GeneratedDataSet/WithMetaDataAndProbabilityFeatures/train.csv'


data = pd.read_csv(dataFilePath, engine='c')
##shuffle data
data = data.sample(frac=1, random_state=2016)
data['classLabel']=(data['classLabel']=='Bug').astype(int)
####Remove duplicate observations/rows
#print("Before", data.shape)
data.drop_duplicates(keep=False,inplace=True)

#print("Data Shape", data.shape)
#noOfNoBuggyCodeRows   = data.loc[data['classLabel'] == 0]
#print("Buggy rows", noOfNoBuggyCodeRows.shape)
#buggyCodeRows = data.loc[data['classLabel'] == 1]
#print("Non-Buggy rows", buggyCodeRows.shape)
#exit()

#print(data.corr())

#print(data.shape)

y = data.classLabel
X = data.drop('classLabel', axis=1)
#X = np.sqrt(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y,random_state=213) #210

#import dataLoader
#(X_train, y_train), (X_test, y_test) = dataLoader.load_dataDNN3()

from sklearn import preprocessing
encoder = preprocessing.LabelEncoder()

# encoding train labels
encoder.fit(y_train)
Y_train = encoder.transform(y_train)

# encoding test labels
encoder.fit(y_test)
Y_test = encoder.transform(y_test)
#print(Y_train)
#print(len(Y_test))

#Total Number of Continous and Categorical features in the training set
num_cols = X_train._get_numeric_data().columns
#print("Number of numeric features:",num_cols.size)

names_of_predictors = list(X_train.columns.values)


# Scaling the Train and Test feature set
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X3_train_scaled = scaler.fit_transform(X_train)
X3_test_scaled = scaler.transform(X_test)


#matplotlib inline
import seaborn as sns
from sklearn.utils import shuffle
#Import Gaussian Naive Bayes model
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.model_selection import cross_val_score, GridSearchCV


print("Start");
#https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-3-cross-validation-and-hyperparameter-tuning/#1.5
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
#https://medium.datadriveninvestor.com/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f
#List Hyperparameters that we want to tune.
#leaf_size = list(range(1,7))
#n_neighbors = [3,5,7,9]
#p=[1,2]

####Best parameter found for data without metadata features
#n_neighbors = [3] #k=log(nbsamples) search range: 1,3,5,7,9
#p=[2]
####Best parameter found for data with metadata features
n_neighbors = [3] #k=log(nbsamples) search range: 1,3,5,7,9
p=[1]

#Convert to dictionary
hyperparameters = dict(n_neighbors=n_neighbors, p=p) #dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)
#Create new KNN object
knn_2 = KNeighborsClassifier()
#Use GridSearch
classifier = GridSearchCV(knn_2, hyperparameters, cv=10)
####Once you find the best hyperparameters, we can use k-fold cross validation and print the results####
validationScores = cross_val_score(classifier, X3_train_scaled, Y_train, cv=10, scoring='accuracy')
print("validationScores:",validationScores.mean())
############################################
#classifier = KNeighborsClassifier(n_neighbors=9)
fitted_model = classifier.fit(X3_train_scaled, Y_train)
print("Fitted");
#print('Best score for training data:', fitted_model.best_score_,"\n")

Y_pred = fitted_model.predict(X3_test_scaled)
Y_pred_label = list(encoder.inverse_transform(Y_pred))


#######Good read to understand precion, recall and F1: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9####
Y3_test_label = list(encoder.inverse_transform(Y_test))
#Print The value of best Hyperparameters
print('Best leaf_size:', fitted_model.best_estimator_.get_params()['leaf_size'])
print('Best p:', fitted_model.best_estimator_.get_params()['p'])
print('Best n_neighbors:', fitted_model.best_estimator_.get_params()['n_neighbors'])

print("Accuracy=",accuracy_score(Y3_test_label,Y_pred_label))
print("\n")
print("Confusion Matrix=",confusion_matrix(Y3_test_label,Y_pred_label))
print("\n")
print("Classification Report=",classification_report(Y3_test_label,Y_pred_label))

print("Training set score for KNN: %f" % fitted_model.score(X3_train_scaled , Y_train))
print("Testing  set score for KNN: %f" % fitted_model.score(X3_test_scaled  , Y_test ))

print("KNN Score = ",fitted_model.score)
#####AUC
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
Y_df = fitted_model.predict_proba(X3_test_scaled)[:,1]

#Binary-class
auc1 = roc_auc_score(Y_test,Y_df)
auc2 = roc_auc_score(Y_test,Y_df)
print("AUC1 = ",auc1)
print("AUC2 = ",auc2)

# PLOT ROC curve
#https://medium.com/cascade-bio-blog/making-sense-of-real-world-data-roc-curves-and-when-to-use-them-90a17e6d1db
from sklearn.metrics import roc_curve, auc
# get false and true positive rates

fpr, tpr, thresholds = roc_curve(Y_test, Y_df, pos_label=1) #pos_label means label of positive class, we can also remove this parameter
# get area under the curve
roc_auc = auc(fpr,tpr)
plt.figure(dpi=150)
plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')
plt.title('ROC Curve for RF classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate (Recall)')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.legend()
plt.show()
#####End AUC
cm = confusion_matrix(Y3_test_label,Y_pred_label)
print(cm)
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(cm)
plt.title('Confusion matrix of the classifier')
fig.colorbar(cax)
ax.set_xticklabels([''] + list(np.unique(Y_pred_label)))
ax.set_yticklabels([''] + list(np.unique(Y_pred_label)))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show(block=True)
plt.interactive(False)

